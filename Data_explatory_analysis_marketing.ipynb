{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhZnDScw5U03QBmVXkmB2B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shaghayegh-Aflatounian/Data-explatory-analysis-marketing/blob/main/Data_explatory_analysis_marketing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for categorical data we need to know how many different values we have per earch subject, for example how many genre of movie we have in our dataset"
      ],
      "metadata": {
        "id": "rAAc6LCRRQ83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required module\n",
        "import pandas as pd\n",
        "\n",
        "# assign data\n",
        "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils',\n",
        "\t\t\t\t\t'Kings', 'kings', 'Kings', 'Kings',\n",
        "\t\t\t\t\t'Riders', 'Royals', 'Royals', 'Riders'],\n",
        "\t\t\t'Rank': [1, 2, 2, 3, 3, 4, 1, 1, 2, 4, 1, 2],\n",
        "\n",
        "\t\t\t'Year': [2014, 2015, 2014, 2015, 2014, 2015, 2016,\n",
        "\t\t\t\t\t2017, 2016, 2014, 2015, 2017],\n",
        "\n",
        "\t\t\t'Points': [876, 789, 863, 673, 741, 812, 756, 788,\n",
        "\t\t\t\t\t694, 701, 804, 690]}\n",
        "\n",
        "# create dataframe\n",
        "df = pd.DataFrame(ipl_data)"
      ],
      "metadata": {
        "id": "ORsHlyAien1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#when we want to convert the data type\n",
        "\n",
        "# Convert is_retained to a boolean\n",
        "marketing['is_retained'] = marketing['is_retained'].astype('bool')\n",
        "\n",
        "# Check the data type of is_retained, again\n",
        "print(marketing['is_retained'].dtype)"
      ],
      "metadata": {
        "id": "3es1QGpwRVpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***make a new boolean and a new column for our dataset***"
      ],
      "metadata": {
        "id": "xDrHQc-ZNhVo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7rtIJE-KpS_"
      },
      "outputs": [],
      "source": [
        "#now we want to define a new boolean item if the addhouse is true if false ,\n",
        "import numpy as np\n",
        "marketing['is-add-house']=np.where(marketing['marketing-channel'])=='add-house','true','false')\n",
        "print(marketing.is-add-house.head(3)) # print(table.column.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inorder to code our dataset with numbers instead of strings and objective which is inefficient we use map\n",
        "channel-dict= {'house'=1 , 'tv'=2}#here we define how we want to code things\n",
        "marketing[code]#here we enter the name of new column we want to put our data set into\n",
        "marketing[code]= marketing['marketing_channel']\\.map(channel-dict)"
      ],
      "metadata": {
        "id": "tVjH4DqmMtrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# note that in       numpy.where()      we put    =="
      ],
      "metadata": {
        "id": "5w0-GIarSlFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering :Adding new columns that derive information from existing data or based on domain knowledge is known as Feature Engineering."
      ],
      "metadata": {
        "id": "92RKAC5yT2-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping for channels\n",
        "channel_dict = {\"House Ads\": 1, \"Instagram\": 2,\n",
        "                \"Facebook\": 3, \"Email\": 4, \"Push\": 5}\n",
        "\n",
        "# Map the channel to a channel code\n",
        "marketing['channel_code'] = marketing['subscribing_channel'].map(channel_dict)\n",
        "\n",
        "# Import numpy\n",
        "import numpy as np\n",
        "# Add the new column is_correct_lang\n",
        "marketing['is_correct_lang'] = np.where(marketing['language_preferred'] == marketing['language_displayed'], 'Yes', 'No')"
      ],
      "metadata": {
        "id": "m-jrkcddT1ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inorder to conver a data type string to a proper we have two ways\n"
      ],
      "metadata": {
        "id": "ouGuMI1sOsDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dealing with data column**"
      ],
      "metadata": {
        "id": "5uzjmEGGVw5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import marketing.csv with date columns\n",
        "marketing = pd.read_csv('marketing.csv',parse_dates=['date_served','date_subscribed','date_canceled'])\n",
        "\n",
        "# Add a DoW column\n",
        "marketing['DoW'] = marketing['date_subscribed'].dt.dayofweek"
      ],
      "metadata": {
        "id": "c3QEat9aVz9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inorder to To see how many people each day see our ads>> user.nunique()\n",
        "Groupby based on data and then sum the total sales  or user.nunique()\n",
        "And its easier to understand and interpret our fluctuations when we plot them\n"
      ],
      "metadata": {
        "id": "1_FENtqOb0cI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by date_served and count number of unique user_id's\n",
        "daily_users = marketing.groupby(['date_served'])['user_id'].nunique()\n",
        "\n",
        "# Print head of daily_users\n",
        "print(daily_users.head())"
      ],
      "metadata": {
        "id": "fsaWKebib19I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#groupby based on sum ::\n",
        "df.groupby(['Team', 'Year'])['Rank'].sum()"
      ],
      "metadata": {
        "id": "8QD9ceWNeqrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inorder to visulize it"
      ],
      "metadata": {
        "id": "22ioS4FydOvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot daily_subscribers\n",
        "daily_users.plot()\n",
        "\n",
        "# Include a title and y-axis label\n",
        "plt.title('Daily users')\n",
        "plt.ylabel('Number of users')\n",
        "\n",
        "# Rotate the x-axis labels by 45 degrees\n",
        "plt.xticks(rotation = 45)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qjdJoFRfdODg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4WXY--lYedI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Marketing Metrics\n",
        "1)Conversion rate"
      ],
      "metadata": {
        "id": "0vK5JoDdf9Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Isolate english speakers\n",
        "english_speakers = marketing[marketing['language_displayed'] == 'English']\n",
        "\n",
        "# Calculate the total number of English speaking users\n",
        "total = english_speakers['user_id'].nunique()\n",
        "\n",
        "# Calculate the number of English speakers who converted\n",
        "subscribers = english_speakers[english_speakers['converted'] == True]\n",
        "subscribers=subscribers['user_id'].nunique()\n",
        "# Calculate conversion rate\n",
        "conversion_rate = subscribers/total\n",
        "print('English speaker conversion rate:', round(conversion_rate*100,2), '%')"
      ],
      "metadata": {
        "id": "xk7lA70JNKW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grouping by and conversion rate\n",
        "# Group by language_displayed and count unique users\n",
        "total = marketing.groupby('language_displayed')['user_id'].nunique()\n",
        "\n",
        "# Group by language_displayed and count unique conversions\n",
        "subscribers =  marketing[marketing['converted']== True].groupby('language_displayed')['user_id'].nunique()\n",
        "\n",
        "\n",
        "# Calculate the conversion rate for all languages\n",
        "language_conversion_rate = subscribers/total\n",
        "print(language_conversion_rate)"
      ],
      "metadata": {
        "id": "cs0FpLEzeVXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to see the effectivness of marketing campagins based on each month or date"
      ],
      "metadata": {
        "id": "FZZ02asHiXAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by date_served and count unique users\n",
        "total = marketing.groupby('date_served')['user_id'].nunique()\n",
        "\n",
        "# Group by date_served and count unique converted users\n",
        "subscribers = marketing[marketing['converted']== True].groupby('date_served')['user_id'].nunique()\n",
        "\n",
        "# Calculate the conversion rate per day\n",
        "daily_conversion_rate = subscribers/total\n",
        "print(daily_conversion_rate)"
      ],
      "metadata": {
        "id": "QOvjyeIDidcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cohort analysis\n",
        "What is cohort analysis? Cohort analysis is a type of behavioral analytics in which you take a group of users, and analyze their usage patterns based on their shared traits to better track and understand their actions. A cohort is simply a group of people with shared characteristics."
      ],
      "metadata": {
        "id": "3Adm4gbwjvsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar chart using language_conversion_rate DataFrame\n",
        "language_conversion_rate.plot(kind='bar')\n",
        "\n",
        "# Add a title and x and y-axis labels\n",
        "plt.title('Conversion rate by language\\n', size =16)\n",
        "plt.ylabel('Conversion rate (%)', size = 14)\n",
        "plt.xlabel('Language', size = 14)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ifNWdM6uied_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inorder to reindex and also rename our columns"
      ],
      "metadata": {
        "id": "bh05jbyv7Hdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_conversion_rate = pd.DataFrame(daily_conversion_rates.reset_index(0))\n",
        "\n",
        "daily_conversion_rate.columns = ['date_served',\n",
        "                              'conversion_rate']"
      ],
      "metadata": {
        "id": "yfsJ_CM27LOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inorder to visulize ourdataframe in a bar chart we first set our bar chart and define it x and y axis and then also set our data point of y to start from 0 because"
      ],
      "metadata": {
        "id": "LR0Ig98N_Qgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a line chart using daily_conversion_rate\n",
        "daily_conversion_rate.plot('date_subscribed','conversion_rate', kind='line')\n",
        "#we indetify on which column we want to set our x and y\n",
        "\n",
        "\n",
        "plt.title('Daily conversion rate\\n', size = 16)\n",
        "plt.ylabel('Conversion rate (%)', size = 14)\n",
        "plt.xlabel('Date', size = 14)\n",
        "\n",
        "# Set the y-axis to begin at 0\n",
        "plt.ylim(0)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "#Consider using plt.autoscale() if you want the y-axis limits to automatically adjust based on the data range."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "rBN6yzJc_hOt",
        "outputId": "e5f91f79-aa6e-464e-da9f-c8fcadfb8b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'daily_conversion_rate' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6b0fd9c2c205>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a line chart using daily_conversion_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdaily_conversion_rate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date_subscribed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'conversion_rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'line'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Daily conversion rate\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'daily_conversion_rate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA MANIUPULATION:\n",
        "1) Inorder to set our column to row we can use 'unstuck' method and set the index to '1 for example if our target row is the second one >> we always put one number low for example first row is 0 # the first index is 0"
      ],
      "metadata": {
        "id": "W0wIcBqAD5Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for line chart as we have for example many language inorder to understand which line belong to which language\n",
        "#we use 'Legend' function"
      ],
      "metadata": {
        "id": "QhWMihqpApVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line chart is goof when we have one argument to measure like language\n",
        "but for example when we have two, it is better to use bar chart"
      ],
      "metadata": {
        "id": "E-oP-PinFRUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "channel_age = marketing.groupby(['marketing_channel', 'age_group'])\\\n",
        "                                ['user_id'].count()\n",
        "\n",
        "# Unstack channel_age and transform it into a DataFrame\n",
        "channel_age_df = pd.DataFrame(channel_age.unstack(level = 1))\n",
        "\n",
        "# Plot channel_age\n",
        "channel_age_df .plot(kind = 'bar')\n",
        "plt.title('Marketing channels by age group')\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Users')\n",
        "# Add a legend to the plot\n",
        "plt.legend(loc = 'upper right',\n",
        "labels = channel_age_df .columns.values)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ucmxMAAqMjWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grouping by multiple column based on those who subscribed"
      ],
      "metadata": {
        "id": "v4hzoODUPOH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum the retained subs by subscribing channel and date subscribed\n",
        "retention_subs = marketing[marketing['converted']==True].groupby(['date_subscribed','subscribing_channel'])['user_id'].nunique()\n",
        "# Print results\n",
        "print(retention_subs.head())"
      ],
      "metadata": {
        "id": "od4UM5MIPNUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide retained subscribers by total subscribers\n",
        "retention_rate = retention_subs/retention_total\n",
        "retention_rate_df = pd.DataFrame(retention_rate.unstack(level=1))\n",
        "\n",
        "# Plot retention rate\n",
        "retention_rate_df.plot()\n",
        "\n",
        "# Add a title, x-label, y-label, legend and display the plot\n",
        "plt.title('Retention Rate by Subscribing Channel')\n",
        "plt.xlabel('Date Subscribed')\n",
        "plt.ylabel('Retention Rate (%)')\n",
        "plt.legend(loc= 'upper right', labels= retention_rate_df.columns.values )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BBqSeJ3FRXTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lets automate the process by defining a subject**"
      ],
      "metadata": {
        "id": "4XNaD6MHXk2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conversion_rate(dataframe, column_names):\n",
        "    # Total number of converted users\n",
        "    column_conv = dataframe[dataframe['converted'] == True]\\\n",
        "                       .groupby(column_names)['user_id'].nunique()\n",
        "\n",
        "    # Total number users\n",
        "    column_total = dataframe.groupby(column_names)['user_id'].nunique()\n",
        "\n",
        "    # Conversion rate\n",
        "    conversion_rate = column_conv/column_total\n",
        "\n",
        "    # Fill missing values with 0\n",
        "    conversion_rate = conversion_rate.fillna(0)\n",
        "    return conversion_rate\n",
        "\n",
        "    # Calculate conversion rate by age_group\n",
        "age_group_conv = conversion_rate(marketing, ['date_served','age_group'])\n",
        "print(age_group_conv)\n",
        "\n",
        "# Unstack and create a DataFrame\n",
        "age_group_df = pd.DataFrame(age_group_conv.unstack(level=1))\n",
        "\n",
        "# Visualize conversion by age_group\n",
        "age_group_df.plot()\n",
        "plt.title('Conversion rate by age group\\n', size = 16)\n",
        "plt.ylabel('Conversion rate', size = 14)\n",
        "plt.xlabel('Age group', size = 14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JOICeJjkXuPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For visulizing through a function**"
      ],
      "metadata": {
        "id": "toaHjQOzfD29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotting_conv(dataframe):\n",
        "    for column in dataframe:\n",
        "        # Plot column by dataframe's index\n",
        "        plt.plot(dataframe.index, dataframe[column])\n",
        "        column.plot()\n",
        "        plt.title('Daily ' + str(column) + ' conversion rate\\n',\n",
        "                  size = 16)\n",
        "        plt.ylabel('Conversion rate', size = 14)\n",
        "        plt.xlabel('Date', size = 14)\n",
        "        # Show plot\n",
        "        plt.show()\n",
        "        plt.clf()"
      ],
      "metadata": {
        "id": "mnoXn9d3fJEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The error is occurring because you are trying to iterate over a function object, which is not iterable. The plotting_conv function is expecting a **dataframe** as input, but you** are passing in the conversion_rate variable**, which seems to be a function instead of a dataframe.\n",
        "plotting_conv(conversion_rate)\n",
        "\n",
        "**like below you should first define your dataframe**"
      ],
      "metadata": {
        "id": "HuEm09eBLKpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate conversion rate by date served and age group\n",
        "age_group_conv = conversion_rate(marketing,['date_served','age_group'])\n",
        "\n",
        "# Unstack age_group_conv and create a DataFrame\n",
        "age_group_df = pd.DataFrame(age_group_conv.unstack(level=1))\n",
        "\n",
        "# Plot the results\n",
        "plotting_conv(age_group_df )"
      ],
      "metadata": {
        "id": "yY4ddM5YjLcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have confirmed that house ads conversion has been down since January 11, you will try to identify potential causes for the decrease.\n",
        "\n",
        "As a data scientist supporting a marketing team, you will run into fluctuating metrics all the time. It's vital to identify if the fluctuations are due to expected shifts in user behavior (i.e., differences across the day of the week) versus a larger problem in technical implementation or marketing strategy.\n",
        "In this exercise, we will begin by checking whether users are more likely to convert on weekends compared with weekdays and determine if that could be the cause for the changing house ads conversion rate."
      ],
      "metadata": {
        "id": "DO6SCgkiMfIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "house_ads =marketing[marketing['marketing_channel']=='House Ads']\n",
        "\n",
        "# Calculate conversion by date served, and language displayed\n",
        "conv_lang_channel = conversion_rate(house_ads,['date_served','language_displayed'])\n",
        "\n",
        "# Unstack conv_lang_channel\n",
        "conv_lang_df = pd.DataFrame(conv_lang_channel.unstack(level=1))\n",
        "\n",
        "# Use your plotting function to display results\n",
        "plotting_conv(conv_lang_df)"
      ],
      "metadata": {
        "id": "vnCxF7WIMiUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***np.where()***"
      ],
      "metadata": {
        "id": "NrB4KaqLpu57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Python\n",
        "numpy.where(condition, x, y)\n",
        "Use code with caution.\n",
        "condition: A boolean array with the same shape as x and y. True elements in condition indicate where to use values from x, and False elements indicate where to use values from y.\n",
        "x, y: Arrays or scalars of the same shape as condition. The values from the corresponding array (either x or y) will be used at each element based on the condition.\n",
        "Functionality:\n",
        "\n",
        "The function iterates over each element in the condition array.\n",
        "For each element:\n",
        "If the condition is True, the corresponding value from the x array is used.\n",
        "If the condition is False, the corresponding value from the y array is used.\n",
        "The function returns a new array with the selected values from x and y based on the condition.\n",
        "Example:\n",
        "\n",
        "Python\n",
        "import numpy as np\n",
        "\n",
        "# Create sample arrays\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "condition = arr > 3\n",
        "\n",
        "# Use numpy.where to replace elements based on the condition\n",
        "new_arr = np.where(condition, arr * 2, arr / 2)\n",
        "\n",
        "# Print the original and modified arrays\n",
        "print(\"Original array:\", arr)\n",
        "print(\"Modified array:\", new_arr)"
      ],
      "metadata": {
        "id": "uw8HlAqfpzwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between the two code snippets lies in how they compare the values in the `language_displayed` column with the `language_preferred` column and assign values to the `is_correct_lang` column based on the comparison.\n",
        "\n",
        "Let's break down the code and explain the differences:\n",
        "\n",
        "First code snippet:\n",
        "```python\n",
        "house_ads['is_correct_lang'] = np.where(\n",
        "    house_ads['language_displayed'] == house_ads['language_preferred'],\n",
        "    'Yes',\n",
        "    'No')\n",
        "```\n",
        "In this code, the `np.where` function is used to perform a conditional check. It compares the values in the `language_displayed` column with the corresponding values in the `language_preferred` column. If the two values are equal, it assigns the value 'Yes' to the `is_correct_lang` column; otherwise, it assigns 'No'.\n",
        "\n",
        "Second code snippet:\n",
        "```python\n",
        "house_ads['is_correct_lang'] = np.where(\n",
        "    house_ads['language_displayed'] == 'language_preferred',\n",
        "    'yes',\n",
        "    'no')\n",
        "```\n",
        "In this code, the `np.where` function is used similarly, but the comparison is made between the values in the `language_displayed` column and the string `'language_preferred'`. So, instead of comparing with the actual values in the `language_preferred` column, it checks if the values in the `language_displayed` column are equal to the string `'language_preferred'`. If the comparison is true, it assigns the value 'yes' to the `is_correct_lang` column; otherwise, it assigns 'no'.\n",
        "\n",
        "The main difference between the two snippets is the comparison being made in the `np.where` function.\n",
        "\n",
        "Regarding the `np.where` function itself, it is a NumPy function that provides a vectorized way to perform conditional checks and assign values based on those checks. It takes three arguments: the condition to check, the value to assign when the condition is true, and the value to assign when the condition is false. It is a concise way to achieve conditional assignments without explicitly using if-else statements.\n",
        "\n",
        "In summary, the difference between the two snippets lies in the comparison being made in the `np.where` function. The first snippet compares with the actual values in the `language_preferred` column, while the second snippet compares with the string `'language_preferred'`."
      ],
      "metadata": {
        "id": "Z3dFgxYDxdhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the new column is_correct_lang\n",
        "house_ads['is_correct_lang'] = np.where(\n",
        "    house_ads['language_displayed'] ==  house_ads['language_preferred'],\n",
        "    'Yes',\n",
        "    'No')\n",
        "\n",
        "# Groupby date_served and correct_language\n",
        "language_check = house_ads.groupby(['date_served', 'is_correct_lang'])['is_correct_lang'].count()\n",
        "\n",
        "\n",
        "\n",
        "# Unstack language_check and fill missing values with 0's\n",
        "language_check_df = pd.DataFrame(language_check.unstack(level=1)).fillna(0)\n",
        "\n",
        "# Print results\n",
        "print(language_check_df)"
      ],
      "metadata": {
        "id": "Kgs0pSnExjIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you've created a DataFrame that checks whether users see ads in the correct language let's calculate what percentage of users were not being served ads in the right language and plot your results.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sN-iRVIH0wlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why do we use language_check_df.index.values,**\n",
        "This uses language_check_df.index.values to access the actual values (dates) associated with each row in the DataFrame's index.\n",
        "This ensures that you're plotting the dates (from the index) on the x-axis and the calculated percentages (\"pct\") on the y-axis."
      ],
      "metadata": {
        "id": "CdePo4IsIRCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Divide the count where language is correct by the row sum\n",
        "language_check_df['pct'] = language_check_df['Yes']/language_check_df.sum(axis=1)\n",
        "\n",
        "# Plot and show your results\n",
        "plt.plot(language_check_df.index.values, language_check_df['pct'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zNdJm1b7FQM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Yes, in pandas DataFrames, axis=1 indeed refers to the rows.\n",
        "\n",
        "\n",
        "axis=0: This means operating along the columns of the DataFrame. For example, df.sum(axis=0) would sum the values in each column, resulting in a Series with the sum of each column.\n",
        "axis=1: This means operating along the rows of the DataFrame. For example, df.sum(axis=1) would sum the values in each row, resulting in a Series with the sum of each row."
      ],
      "metadata": {
        "id": "RxQSDiYn6JL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(language_check_df.index.values, language_check_df['pct'])\n",
        "plt.xlabel('Date Served')\n",
        "plt.ylabel('Percentage of Ads in Correct Language')\n",
        "plt.title('Percentage of Correct Language Ads Over Time')\n",
        "\n"
      ],
      "metadata": {
        "id": "m8VxrD590xZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up conversion indexes\n",
        "Now that you've determined that language is, in fact, the issue with House Ads conversion, stakeholders need to know how many subscribers they lost as a result of this bug.\n",
        "\n",
        "In this exercise, you will index non-English language conversion rates against English conversion rates in the time period before the language bug arose."
      ],
      "metadata": {
        "id": "2HaCYU--MjNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of people we marketed to\n",
        "total = marketing['user_id'].nunique()\n",
        "\n",
        "# Calculate the number of people who subscribed\n",
        "subscribers = marketing[marketing['converted']==True]['user_id'].nunique()\n",
        "\n",
        "# Calculate the conversion rate\n",
        "conversion_rate = subscribers/total\n",
        "print(round(conversion_rate*100, 2), \"%\")"
      ],
      "metadata": {
        "id": "KX5SfA8aRf-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Real conversion rate**"
      ],
      "metadata": {
        "id": "3VyNd6TYNMv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate pre-error conversion rate\n",
        "house_ads_bug = house_ads[house_ads['date_served'] < '2018-01-11']\n",
        "lang_conv = conversion_rate(house_ads_bug,['language_displayed'])\n",
        "\n",
        "# Index other language conversion rate against English\n",
        "spanish_index = lang_conv['Spanish']/lang_conv['English']\n",
        "arabic_index = lang_conv['Arabic']/lang_conv['English']\n",
        "german_index = lang_conv['German']/lang_conv['English']\n",
        "\n",
        "print(\"Spanish index:\", spanish_index)\n",
        "print(\"Arabic index:\", arabic_index)\n",
        "print(\"German index:\", german_index)"
      ],
      "metadata": {
        "id": "3shitKq3Mi8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the true impact of the bug, it is crucial to determine how many subscribers we would have expected had there been no language error. This is crucial to understanding the scale of the problem and how important it is to prevent this kind of error in the future.\n",
        "\n",
        "In this step, you will create a new DataFrame that you can perform calculations on to determine the expected number of subscribers. This DataFrame will include how many users prefer each language by day. Once you have the DataFrame, you can begin calculating how many subscribers you would have expected to have had the language bug not occurred."
      ],
      "metadata": {
        "id": "cs8AploQMfYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We want to calculate the expected conversion rate**"
      ],
      "metadata": {
        "id": "o05WJjVtNQQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group house_ads by date and language\n",
        "converted = house_ads.groupby(['date_served','language_preferred'])\\\n",
        "                        .agg({'user_id':'nunique',\n",
        "                              'converted':'sum'})\n",
        "\n",
        "# Unstack converted\n",
        "converted_df = pd.DataFrame(converted.unstack(level=1))\n",
        "\n",
        "## notice that for agg we use ({})\n",
        "## and for groupby ([])\n",
        "#in agg you define what you exactly want from those grouping by whether its just the sum or the unique number"
      ],
      "metadata": {
        "id": "-LkBiqGuMfyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a DataFrame based on indexes\n",
        "Now that you've created an index to compare English conversion rates against all other languages, you will build out a DataFrame that will estimate what daily conversion rates should have been if users were being served the correct language.\n",
        "\n",
        "An expected conversion DataFrame named converted has been created for you grouping house_ads by date and preferred language. It contains a count of unique users as well as the number of conversions for each language, each day.\n",
        "\n",
        "For example, you can access the number of Spanish-speaking users who received house ads using converted[('user_id','Spanish')]."
      ],
      "metadata": {
        "id": "dsySqAi2Nix9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you've created an index to compare English conversion rates against all other languages, you will build out a DataFrame that will estimate what daily conversion rates should have been if users were being served the correct language.\n",
        "\n",
        "An expected conversion DataFrame named converted has been created for you grouping house_ads by date and preferred language. It contains a count of unique users as well as the number of conversions for each language, each day."
      ],
      "metadata": {
        "id": "YT1nDJMcWdAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create English conversion rate column for affected period\n",
        "converted['english_conv_rate'] = converted.loc['2018-01-11':'2018-01-31'][('converted', 'English')]\n",
        "\n",
        "# Create expected conversion rates for each language\n",
        "converted['expected_spanish_rate'] = converted['english_conv_rate']*spanish_index\n",
        "converted['expected_arabic_rate'] = converted['english_conv_rate']*arabic_index\n",
        "converted['expected_german_rate'] = converted['english_conv_rate']*german_index\n",
        "\n",
        "# Multiply number of users by the expected conversion rate\n",
        "converted['expected_spanish_conv'] = converted['expected_spanish_rate']*converted[('user_id','Spanish')]/100\n",
        "converted['expected_arabic_conv'] = converted['expected_arabic_rate']*converted[('user_id','Arabic')]/100\n",
        "converted['expected_german_conv'] = converted['expected_german_rate']*converted[('user_id','German')]/100"
      ],
      "metadata": {
        "id": "9RCWwj1ENXwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's time to calculate how many subscribers were lost due to mistakenly serving users English rather than their preferred language. Once the team has an estimate of the impact of this error, they can determine whether it's worth putting additional checks in place to avoid this in the future—you might be thinking, of course, it's worth it to try to prevent errors! In a way, you're right, but every choice a company makes requires work and funding. The more information your team has, the better they will be able to evaluate this trade-off.\n",
        "\n",
        "The DataFrame converted has already been loaded for you. It contains expected subscribers columns for Spanish, Arabic and German language speakers named expected_spanish_conv, expected_arabic_conv and expected_german_conv respectively."
      ],
      "metadata": {
        "id": "MxmfvI1hYXhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use .loc to slice only the relevant dates\n",
        "converted = converted.loc['2018-01-11':'2018-01-31']\n",
        "\n",
        "# Sum expected subscribers for each language\n",
        "expected_subs = converted['expected_spanish_conv'].sum() + converted['expected_arabic_conv'].sum() + converted['expected_german_conv'].sum()\n",
        "\n",
        "# Calculate how many subscribers we actually got\n",
        "actual_subs = converted[('converted','Spanish')].sum() + converted[('converted','Arabic')].sum() + converted[('converted','German')].sum()\n",
        "\n",
        "# Subtract how many subscribers we got despite the bug\n",
        "lost_subs = expected_subs - actual_subs\n",
        "print(lost_subs)"
      ],
      "metadata": {
        "id": "KCBNEIshi5CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A/B Test**"
      ],
      "metadata": {
        "id": "Gt-OXey5qa2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The email portion of this campaign was actually run as an A/B test. Half the emails sent out were generic upsells to your product while the other half contained personalized messaging around the users’ usage of the site.\n",
        "\n",
        "Before you begin analyzing the results, you will check to ensure users were allocated equally to the test and control groups."
      ],
      "metadata": {
        "id": "kNLApn9Jqz5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Control group: This group represents the \"normal\" experience, where users see the existing version or no change at all.\n",
        "Test group: This group receives the new variation you're testing, whether it's a new design, feature, or message."
      ],
      "metadata": {
        "id": "6DDvr958rGw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset the DataFrame\n",
        "email = marketing[marketing['marketing_channel']=='Email']\n",
        "\n",
        "# Group the email DataFrame by variant\n",
        "alloc = email.groupby(['variant'])['user_id'].nunique()\n",
        "\n",
        "# Plot a bar chart of the test allocation\n",
        "\n",
        "alloc.plot(kind='bar')\n",
        "plt.title('Personalization test allocation')\n",
        "plt.ylabel('# participants')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a5AyFDlOqd3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A/B Testing**\n",
        "\n"
      ],
      "metadata": {
        "id": "QVJfiFdqv0jQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pay attention to max() function\n",
        "\n",
        "subscribers = email.groupby(['user_id', 'variant']).max()\n",
        "What is the issue?\n",
        "\n",
        "The issue here is that when you use the max() function after grouping by 'user_id' and 'variant', it is trying to find the maximum value for all columns, not just 'converted'. This results in an error because it cannot find the maximum value for non-numeric columns.\n",
        "\n",
        "How do you fix it?\n",
        "\n",
        "To fix this, you should specify that you want to select the maximum value of the 'converted' column specifically. You can do this by changing the line to:\n",
        "\n",
        "subscribers = email.groupby(['user_id', 'variant'])['converted'].max()"
      ],
      "metadata": {
        "id": "x3pYqp8Lv_cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group marketing by user_id and variant\n",
        "subscribers = email.groupby(['user_id', 'variant'])['converted'].max()\n",
        "subscribers_df = pd.DataFrame(subscribers.unstack(level=1))\n",
        "control = subscribers_df['control'].dropna()\n",
        "\n",
        "personalization = subscribers_df['personalization'].dropna()\n",
        "\n",
        "\n",
        "print('Control conversion rate:', np.mean(control))\n",
        "print('Personalization conversion rate:', np.mean(personalization))"
      ],
      "metadata": {
        "id": "V7u_G2gtwZOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XIDy-6C9wmVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o4p7vYqswn04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**T Test in python**"
      ],
      "metadata": {
        "id": "RFL_BYA58UMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "t = ttest_ind( control, personlized)\n",
        "print(t)\n",
        "##The ttest_ind function performs an independent samples t-test, which compares the means of two independent groups."
      ],
      "metadata": {
        "id": "wE5jvJfGA4Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "round(lift*100, 2):\n",
        "\n",
        "The round(x, y) function takes two arguments:\n",
        "x: The value to be rounded (here, lift*100).\n",
        "y: The number of decimal places to round to (here, 2)"
      ],
      "metadata": {
        "id": "flfok2c6JmR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to define a function as much as possible to avoid redundant codings"
      ],
      "metadata": {
        "id": "w_ROti_tOLDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lift(a,b):\n",
        "    # Calcuate the mean of a and b\n",
        "    a_mean = np.mean(a)\n",
        "    b_mean = np.mean(b)\n",
        "\n",
        "    # Calculate the lift using a_mean and b_mean\n",
        "    lift = (b_mean-a_mean)/a_mean\n",
        "\n",
        "    return str(round(lift*100, 2)) + '%'\n",
        "\n",
        "# Print lift() with control and personalization as inputs\n",
        "print(lift(control, personalization))"
      ],
      "metadata": {
        "id": "Kxrv1M-oJhpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is more effective to first segmentize our customers and then specifically for each of our segment we calculate the lift and t value\n",
        "In the previous lesson, you observed that your personalization experiment is highly statistically significant. However, when running experiments, it is important to check how new features are affecting specific demographics. Sometimes features that are highly appealing to one group are less appealing to others.\n",
        "\n",
        "Since you want to segment our data multiple times, you will build a function ab_segmentation() that analyzes the impact of your A/B tests on segments of data that you can reuse each time you want to conduct this kind of analysis.\n",
        "\n",
        "Your function will take in a column name and run through each unique value in that column calculating lift and statistical significance."
      ],
      "metadata": {
        "id": "RhNtRWjc8s_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for language in np.unique(marketing['language_displayed'].values):\n",
        "print(language)\n",
        "language\n",
        "_\n",
        "data = marketing[(marketing['marketing_channel'] == 'Email') &(marketing['language_displayed'] == language)]\n",
        "\n",
        " ## here we use .max() inorder to make sure there is only one channel assign to each user\n",
        "subscribers = language_data.groupby(['user_id','variant'])['converted'].max()\n",
        "subscribers = pd.DataFrame(subscribers.unstack(level=1))\n",
        "control = subscribers['control'].dropna()\n",
        "personalization = subscribers['personalization'].dropna()"
      ],
      "metadata": {
        "id": "CttOF0-23H4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FOR LOOP EXPLANATION**\n",
        "Python\n",
        "cities = ['New York', 'London', 'Paris', 'Tokyo']\n",
        "\n",
        "for city in cities:\n",
        "    print(\"I would like to visit\", city)\n",
        "Use code with caution.\n",
        "Output:\n",
        "\n",
        "I would like to visit New York\n",
        "I would like to visit London\n",
        "I would like to visit Paris\n",
        "I would like to visit Tokyo\n",
        "Explanation:\n",
        "\n",
        "Cities List: We have a list of cities.\n",
        "Variable: We use the variable name city in the for loop, but we could use anything like place, destination, etc.\n",
        "Iterations: The loop goes through each element of the cities list. On each iteration:\n",
        "The city variable takes on the value of the current city from the list.\n",
        "The print statement inside the loop executes, using the value stored in the city variable.\n",
        "Key Points:\n",
        "\n",
        "The variable name in a for loop is arbitrary. Choose names that make your code clearer.\n",
        "The for loop allows you to process items from an iterable sequentially.\n",
        "The code indented within the for loop's block gets executed repeatedly, once for each item."
      ],
      "metadata": {
        "id": "5Cj21npJCsvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cities = ['New York', 'London', 'Paris', 'Tokyo']\n",
        "\n",
        "for city in cities:\n",
        "    print(\"I would like to visit\", city)\n",
        "##The variable name in a for loop is arbitrary. Choose names that make your code clearer."
      ],
      "metadata": {
        "id": "hRja1TMXCzVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(subsegment)\n",
        "\n",
        "      # Limit marketing to email and subsegment\n",
        "      email = marketing[(marketing['marketing_channel'] =='Email') & (marketing[segment] == subsegment)]\n",
        "\n",
        "      subscribers = email.groupby(['user_id', 'variant'])['converted'].max()\n",
        "      subscribers = pd.DataFrame(subscribers.unstack(level=1))\n",
        "      control = subscribers['control'].dropna()\n",
        "      personalization = subscribers['personalization'].dropna()\n"
      ],
      "metadata": {
        "id": "KsSyoYACFI_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ab_segmentation(segment):\n",
        "  # Build a for loop for each subsegment in marketing\n",
        "\n",
        "  ####this part is important if you dont put np.unique you will have many english or ...\n",
        "  for subsegment in np.unique(marketing[segment].values):\n",
        "      print(subsegment)\n",
        "\n",
        "      # Limit marketing to email and subsegment\n",
        "      email = marketing[(marketing['marketing_channel'] == 'Email') & (marketing[segment] == subsegment)]\n",
        "\n",
        "      subscribers = email.groupby(['user_id', 'variant'])['converted'].max()\n",
        "      subscribers = pd.DataFrame(subscribers.unstack(level=1))\n",
        "      control = subscribers['control'].dropna()\n",
        "      personalization = subscribers['personalization'].dropna()\n",
        "\n",
        "      print('lift:', lift(control,personalization))\n",
        "      print('t-statistic:',stats.ttest_ind(control,personalization), '\\n\\n')"
      ],
      "metadata": {
        "id": "ND8tbui2MTNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explaination **:\n",
        "This solution solves the exercise by creating a function ab_segmentation(segment) that takes a segment as an input and performs the required operations on it.\n",
        "\n",
        "The function starts by looping over each unique value in the segment column of the marketing DataFrame. This is done using a for loop and the np.unique() function, which returns an array of unique values in the specified column.\n",
        "\n",
        "Inside the loop, it first prints the current subsegment value. Then, it creates a new DataFrame email that only includes rows from marketing where the marketing_channel is 'Email' and the segment equals the current subsegment. This is done using boolean indexing.\n",
        "\n",
        "Next, it groups the email DataFrame by user_id and variant, and takes the maximum value of the converted column for each group. This results in a DataFrame with user_id as the index and variant as the columns, where each cell represents whether a user has converted or not.\n",
        "\n",
        "Then, it separates the subscribers DataFrame into two Series: control and personalization, which represent the control group and the personalization group, respectively. It drops any missing values in these Series using the dropna() method.\n",
        "\n",
        "Finally, it calculates and prints the lift and the t-statistic between the control and personalization groups. The lift is calculated using the lift() function defined earlier, and the t-statistic is calculated using the stats.ttest_ind() function from the scipy library. The t-statistic is a measure of the difference between the two groups, and can be used to determine if the difference is statistically significant.\n",
        "\n",
        "The function ends by printing two newline characters to separate the output for different subsegments."
      ],
      "metadata": {
        "id": "nLnHFg_yM721"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you've generated an ab_segmentation() function, it's time to test it out.\n",
        "\n",
        "Often a treatment will not affect all people uniformly. Some people will love a particular marketing campaign while others hate it. As a marketing data scientist, it's your responsibility to enable your marketing stakeholders to target users according to their preferences."
      ],
      "metadata": {
        "id": "NY92Qy9hNyHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab_segmentation('age_group')\n",
        "ab_segmentation('language_displayed')"
      ],
      "metadata": {
        "id": "ou6V8CiTNxwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##result :<script.py> output:\n",
        "    Arabic\n",
        "    lift: 50.0%\n",
        "    t-statistic: Ttest_indResult(statistic=-0.5773502691896255, pvalue=0.5795840000000001)\n",
        "\n",
        "\n",
        "    English\n",
        "    lift: 39.0%\n",
        "    t-statistic: Ttest_indResult(statistic=-2.2183598646203166, pvalue=0.026991701290720815)\n",
        "\n",
        "\n",
        "    German\n",
        "    lift: -1.62%\n",
        "    t-statistic: Ttest_indResult(statistic=0.1910083418078718, pvalue=0.8494394170062678)\n",
        "\n",
        "\n",
        "    Spanish\n",
        "    lift: 166.67%\n",
        "    t-statistic: Ttest_indResult(statistic=-2.3570226039551585, pvalue=0.040156718110477524)\n",
        "\n",
        "\n",
        "\n",
        "<script.py> output:\n",
        "    0-18 years\n",
        "    lift: 121.4%\n",
        "    t-statistic: Ttest_indResult(statistic=-2.966044912142211, pvalue=0.0038724494391297226)\n",
        "\n",
        "\n",
        "    19-24 years\n",
        "    lift: 106.24%\n",
        "    t-statistic: Ttest_indResult(statistic=-3.03179438478667, pvalue=0.0030623836114689134)\n",
        "\n",
        "\n",
        "    24-30 years\n",
        "    lift: 161.19%\n",
        "    t-statistic: Ttest_indResult(statistic=-3.861539544326876, pvalue=0.00018743381094867337)\n",
        "\n",
        "\n",
        "    30-36 years\n",
        "    lift: -100.0%\n",
        "    t-statistic: Ttest_indResult(statistic=3.1859064644147996, pvalue=0.0023238487431765137)\n",
        "\n",
        "\n",
        "    36-45 years\n",
        "    lift: -85.23%\n",
        "    t-statistic: Ttest_indResult(statistic=2.4317901279318503, pvalue=0.01797568600978829)\n",
        "\n",
        "\n",
        "    45-55 years\n",
        "    lift: -72.22%\n",
        "    t-statistic: Ttest_indResult(statistic=2.065499127317933, pvalue=0.043062339688201196)\n",
        "\n",
        "\n",
        "    55+ years\n",
        "    lift: -100.0%\n",
        "    t-statistic: Ttest_indResult(statistic=3.3265654564203397, pvalue=0.0016358623456360435)"
      ],
      "metadata": {
        "id": "6VRO49GoOloK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}